{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Lane Detection Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Class to store camera calibration data\n",
    "class calibration():\n",
    "    def __init__(self, obj_pts, img_pts, shape):\n",
    "        self.ret, self.M, self.dist, self.rvecs, self.tvecs =\\\n",
    "        cv2.calibrateCamera(obj_pts, img_pts, shape, None, None)\n",
    "\n",
    "# Class to store transform matrices\n",
    "class transform():\n",
    "    def __init__(self, src, dst):       \n",
    "        self.M = cv2.getPerspectiveTransform(src, dst)\n",
    "        self.Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "        \n",
    "# Class to store lane data\n",
    "class lane():\n",
    "    def __init__(self):\n",
    "        self.detected = False\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "        self.fit = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibrate Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load calibration image filenames\n",
    "fnames = glob.glob('camera_cal/calibration*.jpg')\n",
    "\n",
    "numx = 9 # Number of inner row corners\n",
    "numy = 6 # Number of inner column corners\n",
    "\n",
    "cal_obj_pts = []\n",
    "cal_img_pts = []\n",
    "\n",
    "# Create array of known object points\n",
    "obj_pts = np.zeros((numx*numy, 3), np.float32)\n",
    "obj_pts[:, :2] = np.mgrid[0:numx, 0:numy].T.reshape(-1, 2)\n",
    "\n",
    "# Loop over calibration images\n",
    "for fname in fnames:\n",
    "    img = mpimg.imread(fname) # Load image\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) # Convert image to grayscale\n",
    "    ret, img_pts = cv2.findChessboardCorners(gray, (numx, numy), None) # Detect image points\n",
    "    \n",
    "    # If chessboard corners detected, append object and image points to those previously detected\n",
    "    if ret == True: \n",
    "        cal_obj_pts.append(obj_pts)\n",
    "        cal_img_pts.append(img_pts)\n",
    "\n",
    "# Create an instance of the camera calibration data class\n",
    "cal = calibration(cal_obj_pts, cal_img_pts, img.shape[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Thresholding function\n",
    "def threshold(img, thresh):\n",
    "    binary = np.zeros_like(img)\n",
    "    binary[(img >= thresh[0]) & (img <= thresh[1])] = 1\n",
    "    \n",
    "    return binary\n",
    "\n",
    "# Thresholded absolute Sobel gradient\n",
    "def grad_thresh(img, orient, ksize, thresh):\n",
    "    if orient == 'x':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(img[:, :, 0], cv2.CV_64F, 1, 0, ksize))\n",
    "    \n",
    "    elif orient == 'y':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(img[:, :, 0], cv2.CV_64F, 0, 1, ksize))\n",
    "    \n",
    "    scaled_sobel = np.uint8(abs_sobel*(255/np.max(abs_sobel)))\n",
    "    \n",
    "    return threshold(scaled_sobel, thresh)\n",
    "\n",
    "# Thresholded magnitude of Sobel gradient\n",
    "def mag_thresh(img, ksize, thresh):\n",
    "    sobelx = cv2.Sobel(img[:, :, 0], cv2.CV_64F, 1, 0, ksize)\n",
    "    sobely = cv2.Sobel(img[:, :, 0], cv2.CV_64F, 0, 1, ksize)\n",
    "    \n",
    "    mag_sobelxy = np.sqrt(sobelx**2 + sobely**2)\n",
    "    \n",
    "    scaled_sobel = np.uint8(mag_sobelxy*(255/np.max(mag_sobelxy)))\n",
    "\n",
    "    return threshold(scaled_sobel, thresh)\n",
    "\n",
    "# Thresholded direction of Sobel gradient\n",
    "def dir_thresh(img, ksize, thresh):\n",
    "    abs_sobelx = np.absolute(cv2.Sobel(img[:, :, 0], cv2.CV_64F, 1, 0, ksize))\n",
    "    abs_sobely = np.absolute(cv2.Sobel(img[:, :, 0], cv2.CV_64F, 0, 1, ksize))\n",
    "    \n",
    "    dir_sobelxy = np.arctan2(abs_sobely, abs_sobelx)\n",
    "    \n",
    "    return threshold(dir_sobelxy, thresh)\n",
    "\n",
    "# Warp image perspective\n",
    "def warp(img, view):\n",
    "    # Warp image perspective into bird's eye view\n",
    "    if view == 'b':\n",
    "        warped = cv2.warpPerspective(img, trans.M, (img.shape[1], img.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "        \n",
    "    # Warp image perspective into driver's view\n",
    "    elif view == 'd':\n",
    "        warped = cv2.warpPerspective(img, trans.Minv, (img.shape[1], img.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    return warped\n",
    "\n",
    "# Find initial lane locations\n",
    "def find_initial(img):\n",
    "    histogram = np.sum(img[img.shape[0]*(3/4):, :], axis=0) \n",
    "    midpoint = histogram.shape[0]//2\n",
    "    \n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint \n",
    "\n",
    "    left.x, left.y = find_initial_sub(img, leftx_base)\n",
    "    right.x, right.y = find_initial_sub(img, rightx_base)\n",
    "    \n",
    "    left.fit = np.polyfit(left.y, left.x, 2)\n",
    "    right.fit = np.polyfit(right.y, right.x, 2)\n",
    "    \n",
    "    left.detected = True\n",
    "    right.detected = True\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Find initial lane locations - sub function\n",
    "def find_initial_sub(img, xbase):\n",
    "    num_windows = 9   \n",
    "    window_height = img.shape[0]//num_windows # 80\n",
    "    margin = 80\n",
    "    min_pix = 800\n",
    "    \n",
    "    non_zeroy = np.array(img.nonzero()[0])\n",
    "    non_zerox = np.array(img.nonzero()[1])\n",
    "    \n",
    "    lane_inds = []\n",
    "    shift = 0\n",
    "    \n",
    "    # Sliding window technique\n",
    "    for window in range(num_windows):\n",
    "        winy_low = img.shape[0] - (window + 1)*window_height # Window lower bound\n",
    "        winy_high = img.shape[0] - window*window_height # Window upper bound\n",
    "\n",
    "        winx_left = xbase - margin # Window left bound\n",
    "        winx_right = xbase + margin # Window right bound\n",
    "\n",
    "        lane_inds_cur = ((non_zeroy >= winy_low) & (non_zeroy < winy_high) &\\\n",
    "                          (non_zerox >= winx_left) & (non_zerox < winx_right)).nonzero()[0]\n",
    "\n",
    "        lane_inds.append(lane_inds_cur)\n",
    "        \n",
    "        # Center window on average of detected non-zero pixels\n",
    "        if len(lane_inds_cur) > min_pix:\n",
    "            xbase_new = np.int(np.mean(non_zerox[lane_inds_cur]))\n",
    "            shift = xbase_new - xbase\n",
    "            xbase = xbase_new\n",
    "        \n",
    "        # Shift window by previous amount\n",
    "        else:\n",
    "            xbase += shift\n",
    "        \n",
    "\n",
    "    lane_inds = np.concatenate(lane_inds)\n",
    "\n",
    "    return non_zerox[lane_inds], non_zeroy[lane_inds]\n",
    "\n",
    "# Find lane locations using margin around previous lane locations\n",
    "def find_next(img):\n",
    "    leftx, lefty = find_next_sub(img, left.fit)\n",
    "    rightx, righty = find_next_sub(img, right.fit)\n",
    "    \n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    # Check whether current lanes are within margin of previous lanes\n",
    "    if np.all([((left_fit[2] > left.fit[2]*0.8) & (left_fit[2] < left.fit[2]*1.2)),\\\n",
    "               ((right_fit[2] > right.fit[2]*0.8) & (right_fit[2] < right.fit[2]*1.2))]):\n",
    "        \n",
    "        # Compute weighted average of current and previous polynomial coefficients\n",
    "        # based on number of non-zero pixels detected\n",
    "        left_weights = np.array([(len(leftx)/(len(leftx) + len(left.x))),\\\n",
    "                                 (len(left.x)/(len(leftx) + len(left.x)))])\n",
    "\n",
    "        right_weights = np.array([(len(rightx)/(len(rightx) + len(right.x))),\\\n",
    "                                 (len(right.x)/(len(rightx) + len(right.x)))])\n",
    "\n",
    "        left.fit = np.average((left_fit, left.fit), axis = 0, weights = left_weights)\n",
    "        right.fit = np.average((right_fit, right.fit), axis = 0, weights = right_weights)\n",
    "\n",
    "        left.x, left.y = leftx, lefty\n",
    "        right.x, right.y = rightx, righty\n",
    "    \n",
    "    # If current lanes outside of margin of previous lanes detect lanes from scratch\n",
    "    else:\n",
    "        find_initial(img)\n",
    "    \n",
    "    return None\n",
    "\n",
    "def find_next_sub(img, fit):\n",
    "    margin = 80\n",
    "    \n",
    "    non_zeroy = np.array(img.nonzero()[0])\n",
    "    non_zerox = np.array(img.nonzero()[1])\n",
    "    \n",
    "    # Detect non-zero pixels within previously computed polynomial +/- margin\n",
    "    lane_inds = ((non_zerox > (fit[0]*(non_zeroy**2) + fit[1]*non_zeroy + fit[2] - margin)) &\\\n",
    "                 (non_zerox < (fit[0]*(non_zeroy**2) + fit[1]*non_zeroy + fit[2] + margin)))\n",
    "    \n",
    "    return non_zerox[lane_inds], non_zeroy[lane_inds]\n",
    "\n",
    "# Calculate road curvature radius and vehicle relation to lane center\n",
    "def info(shape):\n",
    "    \n",
    "    # Lane base x-points\n",
    "    leftx_base = np.mean(left.x[(left.y >= shape[0]*(3/4))])\n",
    "    rightx_base = np.mean(right.x[(right.y >= shape[0]*(3/4))]) \n",
    "    \n",
    "    # Pixel to meter conversion factors\n",
    "    xconv = 3.7/(rightx_base - leftx_base)\n",
    "    yconv = 30/720\n",
    "    \n",
    "    # Lane polynomial coefficients\n",
    "    left_fit = np.polyfit(left.y*yconv, left.x*xconv, 2)\n",
    "    right_fit = np.polyfit(right.y*yconv, right.x*xconv, 2)\n",
    "    \n",
    "    # Average of lane polynomial coefficients\n",
    "    fit = np.mean((left_fit, right_fit), axis = 0)\n",
    "    \n",
    "    # Road curvature radius\n",
    "    curve_rad = (((1 + (2*fit[0]*shape[0]*yconv + fit[1])**2)**1.5)/np.absolute(2*fit[0]))\n",
    "    \n",
    "    # Vehicle relation to lane center\n",
    "    off_center = (shape[1]/2 - np.mean((leftx_base, rightx_base)))*xconv\n",
    "    \n",
    "    return curve_rad, off_center\n",
    "\n",
    "# Draw identified lane and road information on image\n",
    "def draw_lane(img):\n",
    "    blank = np.zeros_like(img).astype(np.uint8)\n",
    "    \n",
    "    ploty = np.linspace(0, blank.shape[0] - 1, blank.shape[0])\n",
    "    \n",
    "    leftx = left.fit[0]*ploty**2 + left.fit[1]*ploty + left.fit[2]\n",
    "    rightx = right.fit[0]*ploty**2 + right.fit[1]*ploty + right.fit[2]\n",
    "    \n",
    "    left_pts = np.array([np.transpose(np.vstack([leftx, ploty]))])\n",
    "     # Flip right points to order polygon points from top to bottom left to bottom to top right\n",
    "    right_pts = np.array([np.flipud(np.transpose(np.vstack([rightx, ploty])))])\n",
    "    pts = np.hstack((left_pts, right_pts))\n",
    "\n",
    "    return cv2.fillPoly(blank, np.int_([pts]), (0, 255, 0))\n",
    "\n",
    "# Draw road curvature radius and vehicle relation to lane center on image\n",
    "def draw_info(img):\n",
    "    curve_rad, off_center = info(img.shape)\n",
    "    \n",
    "    curve_text = 'Curvature radius = {:d}m'.format(int(curve_rad))\n",
    "    \n",
    "    if off_center < 0:\n",
    "        off_text = 'Vehicle {:.2f}m left of center'.format(abs(off_center))\n",
    "        arrow = '>'\n",
    "        arrow_pos = (1110, 620)\n",
    "    \n",
    "    elif off_center > 0:\n",
    "        off_text = 'Vehicle {:.2f}m right of center'.format(abs(off_center))\n",
    "        arrow = '<'\n",
    "        arrow_pos = (100, 620)\n",
    "    \n",
    "    if abs(off_center) <= 0.25:\n",
    "        arrow_col = (0, 255, 0)\n",
    "        \n",
    "    elif (abs(off_center) > 0.25) & (abs(off_center) <= 0.5):\n",
    "        arrow_col = (255, 255, 0)\n",
    "        \n",
    "    elif abs(off_center) > 0.5:\n",
    "        arrow_col = (255, 0, 0)\n",
    "    \n",
    "    # Draw curvature radius on image\n",
    "    cv2.putText(img, curve_text, org = (10, 30), fontFace = cv2.FONT_HERSHEY_SIMPLEX,\\\n",
    "                fontScale = 1, thickness = 2, color = (0, 255, 0), bottomLeftOrigin = False)\n",
    "    \n",
    "    # Draw vehicle relation to lane center on image\n",
    "    cv2.putText(img, off_text, org = (10, 60), fontFace = cv2.FONT_HERSHEY_SIMPLEX,\\\n",
    "                       fontScale = 1, thickness = 2, color = (0, 255, 0), bottomLeftOrigin = False)\n",
    "    \n",
    "    # Draw turn correction arrow on image\n",
    "    return cv2.putText(img, arrow, org = arrow_pos, fontFace = cv2.FONT_HERSHEY_SIMPLEX,\\\n",
    "                       fontScale = 4, thickness = 4, color = arrow_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pipeline(img):\n",
    "    \n",
    "    # Undistort image using previously computed camera calibration matrix\n",
    "    img = cv2.undistort(img, cal.M, cal.dist, None, cal.M)\n",
    "    \n",
    "    # Threshold image\n",
    "    binary_gradx = grad_thresh(img, orient = 'x', ksize = 3, thresh = (20, 255))\n",
    "    binary_grady = grad_thresh(img, orient = 'y', ksize = 3, thresh = (20, 255))\n",
    "    \n",
    "    binary_grad_mag = mag_thresh(img, ksize = 3, thresh = (40, 255))\n",
    "    binary_grad_dir = dir_thresh(img, ksize = 3, thresh = (0.7, 1.3))\n",
    "    \n",
    "    binary_rch = threshold(img[:, :, 0], thresh = (140, 255))\n",
    "    binary_sch = threshold(cv2.cvtColor(img, cv2.COLOR_RGB2HLS)[:, :, 2],\\\n",
    "                           thresh = (100, 255))\n",
    "    \n",
    "    # Combine binary images\n",
    "    combined = np.zeros_like(binary_gradx)\n",
    "    combined[((binary_gradx == 1) & (binary_grady == 1)) |\\\n",
    "                ((binary_grad_mag == 1) & (binary_grad_dir == 1)) |\\\n",
    "                ((binary_rch == 1) & (binary_sch == 1))] = 1\n",
    "    \n",
    "    # Warp image perspective into bird's eye view\n",
    "    warped = warp(combined, view = 'b')\n",
    "    \n",
    "    # Find lane locations from scratch\n",
    "    if left.detected == False & right.detected == False:\n",
    "        find_initial(warped)\n",
    "    \n",
    "    # Find lane locations using margin around previously found lane locations\n",
    "    elif left.detected == True & right.detected == True:\n",
    "        find_next(warped)\n",
    "\n",
    "    lane = draw_lane(img)\n",
    "    unwarped = warp(lane, view = 'd')\n",
    "    projected = cv2.addWeighted(img, 1, unwarped, 0.3, 0)\n",
    "    \n",
    "    return draw_info(projected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiate Class Instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "src = np.float32([[685, 450],\n",
    "                  [1090, 720],\n",
    "                  [190, 720],\n",
    "                  [595, 450]])\n",
    "\n",
    "dst = np.float32([[990, 0],\n",
    "                  [990, 720],\n",
    "                  [290, 720],\n",
    "                  [290, 0]])\n",
    "\n",
    "trans = transform(src, dst)\n",
    "\n",
    "left = lane()\n",
    "right = lane()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video videos/output/project_video.mp4\n",
      "[MoviePy] Writing video videos/output/project_video.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1260/1261 [05:53<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: videos/output/project_video.mp4 \n",
      "\n",
      "CPU times: user 9min 4s, sys: 1min 17s, total: 10min 21s\n",
      "Wall time: 5min 54s\n"
     ]
    }
   ],
   "source": [
    "video_output = 'videos/output/project_video.mp4'\n",
    "video_input = VideoFileClip('videos/input/project_video.mp4')\n",
    "video_clip = video_input.fl_image(pipeline)\n",
    "%time video_clip.write_videofile(video_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"videos/output/project_video.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(video_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
